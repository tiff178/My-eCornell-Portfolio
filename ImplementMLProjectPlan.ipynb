{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Implement Your Machine Learning Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will implement the machine learning project plan you created in the written assignment. You will:\n",
    "\n",
    "1. Load your data set and save it to a Pandas DataFrame.\n",
    "2. Perform exploratory data analysis on your data to determine which feature engineering and data preparation techniques you will use.\n",
    "3. Prepare your data for your model and create features and a label.\n",
    "4. Fit your model to the training data and evaluate your model.\n",
    "5. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow.keras as keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the Data Set\n",
    "\n",
    "\n",
    "You have chosen to work with one of four data sets. The data sets are located in a folder named \"data.\" The file names of the three data sets are as follows:\n",
    "\n",
    "* The \"adult\" data set that contains Census information from 1994 is located in file `adultData.csv`\n",
    "* The airbnb NYC \"listings\" data set is located in file  `airbnbListingsData.csv`\n",
    "* The World Happiness Report (WHR) data set is located in file `WHR2018Chapter2OnlineData.csv`\n",
    "* The book review data set is located in file `bookReviewsData.csv`\n",
    "\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load your data using `pd.read_csv()` and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "The next step is to inspect and analyze your data set with your machine learning problem and project plan in mind. \n",
    "\n",
    "This step will help you determine data preparation and feature engineering techniques you will need to apply to your data to build a balanced modeling data set for your problem and model. These data preparation techniques may include:\n",
    "* addressing missingness, such as replacing missing values with means\n",
    "* renaming features and labels\n",
    "* finding and replacing outliers\n",
    "* performing winsorization if needed\n",
    "* performing one-hot encoding on categorical features\n",
    "* performing vectorization for an NLP problem\n",
    "* addressing class imbalance in your data sample to promote fair AI\n",
    "\n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. \n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # inspect the first few rows of Book Review data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # get insight into key statistics for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the label - Positive Review\n",
    "print(df['Positive Review'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of reviews - more negative than positive reviews\n",
    "sns.countplot(x='Positive Review', data=df)\n",
    "plt.title('Distribution of Positive Reviews')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. You will:\n",
    "\n",
    "1. Prepare your data for your model and create features and a label.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labeled examples\n",
    "y = df['Positive Review'] # label\n",
    "X = df['Review'] # feature\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labeled examples into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)\n",
    "\n",
    "X_train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000) \n",
    "\n",
    "# fit and transform the training data\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# transform the test data\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=1234)\n",
    "\n",
    "# train the model on the training data\n",
    "lr_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = lr_model.predict(X_test_vec)\n",
    "\n",
    "# calculate F1-score to evaluate the model's performance\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# visualize the confusion matrix - better understanding of distribution of true (or false) positives/negatives\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore additional features/techniques that may enhance model's performance - TF-IDF\n",
    "# create a TfidfVectorizer object \n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit the vectorizer to X_train\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# using the fitted vectorizer, transform the training data \n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "\n",
    "# using the fitted vectorizer, transform the test data \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when constructing neural network, specify the input_shape - meaning the dimensionality of the input layer\n",
    "# this corresponds to the dimension of each of the training examples, which is our vocabulary size.\n",
    "vocabulary_size = len(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object\n",
    "nn_model = keras.Sequential()\n",
    "\n",
    "# create the input layer and add it to the model object: \n",
    "input_layer = keras.layers.InputLayer(input_shape=(vocabulary_size,))\n",
    "\n",
    "# add input_layer to the model object:\n",
    "nn_model.add(input_layer)\n",
    "\n",
    "# create the first hidden layer and add it to the model object:\n",
    "hidden_layer_1 = keras.layers.Dense(units=64, activation='relu')\n",
    "nn_model.add(hidden_layer_1)\n",
    "nn_model.add(keras.layers.Dropout(.25)) # dropout - add randomness & prevent overfitting\n",
    "\n",
    "# create the second layer and add it to the model object:\n",
    "hidden_layer_2 = keras.layers.Dense(units=32, activation='relu')\n",
    "nn_model.add(hidden_layer_2)\n",
    "nn_model.add(keras.layers.Dropout(.25)) # dropout - add randomness & prevent overfitting\n",
    "\n",
    "# create the third layer and add it to the model object:\n",
    "hidden_layer_3 = keras.layers.Dense(units=16, activation='relu')\n",
    "\n",
    "# add hidden_layer_3 to the model object:\n",
    "nn_model.add(hidden_layer_3)\n",
    "nn_model.add(keras.layers.Dropout(.25)) # dropout - add randomness & prevent overfitting\n",
    "\n",
    "# create the output layer and add it to the model object:\n",
    "output_layer = keras.layers.Dense(units=1, activation='sigmoid')\n",
    "nn_model.add(output_layer)\n",
    "\n",
    "# print summary of neural network model structure\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimization function\n",
    "sgd_optimizer = keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# compile the model\n",
    "nn_model.compile(optimizer=sgd_optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback class to output info from model when training\n",
    "class ProgBarLoggerNEpochs(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, num_epochs: int, every_n: int = 50):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.every_n = every_n\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.every_n == 0:\n",
    "            s = 'Epoch [{}/ {}]'.format(epoch + 1, self.num_epochs)\n",
    "            logs_s = ['{}: {:.4f}'.format(k.capitalize(), v)\n",
    "                      for k, v in logs.items()]\n",
    "            s_list = [s] + logs_s\n",
    "            print(', '.join(s_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the neural network model to the vectorized training data\n",
    "t0 = time.time() # start time\n",
    "\n",
    "num_epochs = 38 #epochs\n",
    "\n",
    "history = nn_model.fit(X_train_tfidf.toarray(), y_train, epochs=num_epochs, verbose=0,\n",
    "                      callbacks=[ProgBarLoggerNEpochs(num_epochs, every_n=50)], validation_split=0.2)\n",
    "\n",
    "t1 = time.time() # stop time\n",
    "\n",
    "print('Elapsed time: %.2fs' % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model's performance over time \n",
    "# plot training and validation loss\n",
    "plt.plot(range(1, num_epochs + 1), history.history['loss'], label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot training and validation accuracy\n",
    "plt.plot(range(1, num_epochs + 1), history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of the model \n",
    "loss, accuracy = nn_model.evaluate(X_test_tfidf.toarray(), y_test)\n",
    "\n",
    "print('Loss: ', str(loss) , 'Accuracy: ', str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "probability_predictions = nn_model.predict(X_test_tfidf.toarray())\n",
    "\n",
    "print(\"Predictions for the first 10 examples:\")\n",
    "print(\"Probability\\t\\t\\tClass\")\n",
    "for i in range(0,10):\n",
    "    if probability_predictions[i] >= .5:\n",
    "        class_pred = \"Good Review\"\n",
    "    else:\n",
    "        class_pred = \"Bad Review\"\n",
    "    print(str(probability_predictions[i]) + \"\\t\\t\\t\" + str(class_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify if model accurately predicted whether reviews are good or bad reviews\n",
    "print('Review #1:\\n')\n",
    "print(X_test.to_numpy()[50])\n",
    "\n",
    "goodReview = True if probability_predictions[50] >= .5 else False\n",
    "    \n",
    "print('\\nPrediction: Is this a good review? {}\\n'.format(goodReview))\n",
    "\n",
    "print('Actual: Is this a good review? {}\\n'.format(y_test.to_numpy()[50]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**My Analysis/Observations**: \n",
    "After implementing my project plan, it seems like logistic regression is slightly better than TF-IDF. Observing the F1-score, the higher the F1-score - it's better because it indicates a good balance between precision and recall, suggesting that the model is making accurate positive predictions while identifying a high proportion of actual positive instances. With TF-IDF (similar to what we have done in Lab 7), adjusting the number of epochs and dropout layers may affect the changes but the best accuracy/loss ratio I could get was with dropout layers for all 3 hidden layers and epochs of 38. The confusion matrix also helped visualize any possible errors. Through this, I learned that even though I have tested one specific method (e.g. logistic regression) for this particular dataset, I should always consider exploring additional features/techniques that may enhance the model's performance. Exploring what works, what is better, and what is the best for this data set/problem is important before deploying the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
